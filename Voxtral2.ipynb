{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIJXNTD7QyiqLshxQ8b65O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAMeh-ZAGhloul/Mistral-Voxtral/blob/main/Voxtral2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-HOM8yQbq6K",
        "outputId": "5366f25a-d61c-4c1f-938e-d52860fe85dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'voxtral-test' already exists and is not an empty directory.\n",
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Jul 16 13:48 sample_data\n",
            "drwxr-xr-x 3 root root 4096 Jul 18 22:04 voxtral-test\n"
          ]
        }
      ],
      "source": [
        "#https://github.com/coezbek/voxtral-test\n",
        "\n",
        "! git clone https://github.com/coezbek/voxtral-test\n",
        "! ls -l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! uv pip install -q -U \"vllm[audio]\" --torch-backend=cu126 --extra-index-url https://wheels.vllm.ai/nightly\n",
        "! uv pip install -q -U mistral_common\\[audio\\] \"numpy<2.3\""
      ],
      "metadata": {
        "id": "e83BF2l3b7K1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python -c \"import mistral_common; print(mistral_common.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3dCNvq9e2FC",
        "outputId": "f2c6ae22-d78e-42da-d348-88c4f5b0bc87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4ljb0vjj0Hd",
        "outputId": "80b0f06b-2563-4fe0-8512-1be62c77bce5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 18 22:08:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! vllm serve mistralai/Voxtral-Mini-3B-2507 --port 8333 --tokenizer_mode mistral --config_format mistral --load_format mistral --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhYyUuvucIah",
        "outputId": "22320f08-da5a-44b3-be30-e255caec39f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-18 22:08:40.317638: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752876520.349709    2028 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752876520.359805    2028 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-18 22:08:40.392057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "INFO 07-18 22:08:45 [__init__.py:235] Automatically detected platform cuda.\n",
            "WARNING 07-18 22:08:49 [__init__.py:1676] argument 'device' is deprecated\n",
            "INFO 07-18 22:08:49 [api_server.py:1651] vLLM API server version 0.9.2rc2.dev340+g0f199f197\n",
            "INFO 07-18 22:08:49 [cli_args.py:298] non-default args: {'model_tag': 'mistralai/Voxtral-Mini-3B-2507', 'port': 8333, 'model': 'mistralai/Voxtral-Mini-3B-2507', 'tokenizer_mode': 'mistral', 'config_format': 'mistral', 'load_format': 'mistral', 'device': 'cuda'}\n",
            "Parse safetensors files: 100% 2/2 [00:00<00:00,  7.41it/s]\n",
            "INFO 07-18 22:09:04 [config.py:3473] Downcasting torch.float32 to torch.float16.\n",
            "INFO 07-18 22:09:04 [config.py:1565] Using max model len 32768\n",
            "WARNING 07-18 22:09:04 [arg_utils.py:1730] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
            "INFO 07-18 22:09:04 [api_server.py:268] Started engine process with PID 2171\n",
            "/usr/local/lib/python3.11/dist-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.\n",
            "  warnings.warn(\n",
            "2025-07-18 22:09:09.398987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752876549.418638    2171 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752876549.424523    2171 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "INFO 07-18 22:09:14 [__init__.py:235] Automatically detected platform cuda.\n",
            "INFO 07-18 22:09:17 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2rc2.dev340+g0f199f197) with config: model='mistralai/Voxtral-Mini-3B-2507', speculative_config=None, tokenizer='mistralai/Voxtral-Mini-3B-2507', skip_tokenizer_init=False, tokenizer_mode=mistral, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.MISTRAL, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Voxtral-Mini-3B-2507, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":256,\"local_cache_dir\":null}, use_cached_outputs=True, \n",
            "/usr/local/lib/python3.11/dist-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.\n",
            "  warnings.warn(\n",
            "generation_config.json: 100% 108/108 [00:00<00:00, 774kB/s]\n",
            "INFO 07-18 22:09:20 [cuda.py:353] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 07-18 22:09:20 [cuda.py:402] Using XFormers backend.\n",
            "INFO 07-18 22:09:21 [parallel_state.py:1090] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 07-18 22:09:21 [model_runner.py:1175] Starting to load model mistralai/Voxtral-Mini-3B-2507...\n",
            "INFO 07-18 22:09:23 [cuda.py:353] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 07-18 22:09:23 [cuda.py:402] Using XFormers backend.\n",
            "INFO 07-18 22:09:24 [weight_utils.py:296] Using model weights format ['consolidated*.safetensors', '*.pt']\n",
            "consolidated.safetensors: 100% 9.35G/9.35G [01:53<00:00, 82.5MB/s]\n",
            "INFO 07-18 22:11:17 [weight_utils.py:312] Time spent downloading weights for mistralai/Voxtral-Mini-3B-2507: 113.744001 seconds\n",
            "INFO 07-18 22:11:18 [weight_utils.py:349] No consolidated.safetensors.index.json found in remote.\n",
            "Loading safetensors checkpoint shards: 100% 1/1 [00:35<00:00, 35.02s/it]\n",
            "INFO 07-18 22:11:53 [default_loader.py:262] Loading weights took 35.14 seconds\n",
            "INFO 07-18 22:11:54 [model_runner.py:1207] Model loading took 8.7223 GiB and 151.567585 seconds\n",
            "WARNING 07-18 22:11:56 [registry.py:184] VoxtralProcessorAdapter did not return `BatchFeature`. Make sure to match the behaviour of `ProcessorMixin` when implementing custom processors.\n",
            "/usr/local/lib/python3.11/dist-packages/mistral_common/tokens/tokenizers/tekken.py:461: FutureWarning: Using the tokenizer's special token policy (SpecialTokenPolicy.IGNORE) is deprecated. It will be removed in 1.10.0. Please pass a special token policy explicitly. Future default will be SpecialTokenPolicy.IGNORE.\n",
            "  warnings.warn(\n",
            "WARNING 07-18 22:11:56 [profiling.py:237] The sequence length used for profiling (max_num_batched_tokens / max_num_seqs = 32768) is too short to hold the multi-modal embeddings in the worst case (33004 tokens in total, out of which {'audio': 33000} are reserved for multi-modal embeddings). This may cause certain multi-modal inputs to fail during inference, even when the input text is short. To avoid this, you should increase `max_model_len`, reduce `max_num_seqs`, and/or reduce `mm_counts`.\n",
            "INFO 07-18 22:12:53 [worker.py:295] Memory profiling takes 59.05 seconds\n",
            "INFO 07-18 22:12:53 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
            "INFO 07-18 22:12:53 [worker.py:295] model weights take 8.72GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 3.93GiB; the rest of the memory reserved for KV Cache is 0.56GiB.\n",
            "INFO 07-18 22:12:53 [executor_base.py:115] # cuda blocks: 304, # CPU blocks: 2184\n",
            "INFO 07-18 22:12:53 [executor_base.py:120] Maximum concurrency for 32768 tokens per request: 0.15x\n",
            "ERROR 07-18 22:12:53 [engine.py:458] The model's max seq len (32768) is larger than the maximum number of tokens that can be stored in KV cache (4864). Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine.\n",
            "ERROR 07-18 22:12:53 [engine.py:458] Traceback (most recent call last):\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 446, in run_mp_engine\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     engine = MQLLMEngine.from_vllm_config(\n",
            "ERROR 07-18 22:12:53 [engine.py:458]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 133, in from_vllm_config\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     return cls(\n",
            "ERROR 07-18 22:12:53 [engine.py:458]            ^^^^\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 87, in __init__\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     self.engine = LLMEngine(*args, **kwargs)\n",
            "ERROR 07-18 22:12:53 [engine.py:458]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 268, in __init__\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     self._initialize_kv_caches()\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 426, in _initialize_kv_caches\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/executor_base.py\", line 126, in initialize_cache\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     self.collective_rpc(\"initialize_cache\",\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/uniproc_executor.py\", line 57, in collective_rpc\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     answer = run_method(self.driver_worker, method, args, kwargs)\n",
            "ERROR 07-18 22:12:53 [engine.py:458]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/utils/__init__.py\", line 2991, in run_method\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     return func(*args, **kwargs)\n",
            "ERROR 07-18 22:12:53 [engine.py:458]            ^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 319, in initialize_cache\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     raise_if_cache_size_invalid(\n",
            "ERROR 07-18 22:12:53 [engine.py:458]   File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 595, in raise_if_cache_size_invalid\n",
            "ERROR 07-18 22:12:53 [engine.py:458]     raise ValueError(\n",
            "ERROR 07-18 22:12:53 [engine.py:458] ValueError: The model's max seq len (32768) is larger than the maximum number of tokens that can be stored in KV cache (4864). Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine.\n",
            "Process SpawnProcess-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 460, in run_mp_engine\n",
            "    raise e from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 446, in run_mp_engine\n",
            "    engine = MQLLMEngine.from_vllm_config(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 133, in from_vllm_config\n",
            "    return cls(\n",
            "           ^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 87, in __init__\n",
            "    self.engine = LLMEngine(*args, **kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 268, in __init__\n",
            "    self._initialize_kv_caches()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 426, in _initialize_kv_caches\n",
            "    self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/executor_base.py\", line 126, in initialize_cache\n",
            "    self.collective_rpc(\"initialize_cache\",\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/uniproc_executor.py\", line 57, in collective_rpc\n",
            "    answer = run_method(self.driver_worker, method, args, kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/utils/__init__.py\", line 2991, in run_method\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 319, in initialize_cache\n",
            "    raise_if_cache_size_invalid(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 595, in raise_if_cache_size_invalid\n",
            "    raise ValueError(\n",
            "ValueError: The model's max seq len (32768) is larger than the maximum number of tokens that can be stored in KV cache (4864). Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine.\n",
            "[rank0]:[W718 22:12:54.903754938 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/vllm\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/cli/main.py\", line 54, in main\n",
            "    args.dispatch_function(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/cli/serve.py\", line 57, in cmd\n",
            "    uvloop.run(run_server(args))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 105, in run\n",
            "    return runner.run(wrapper())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 61, in wrapper\n",
            "    return await main\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 1687, in run_server\n",
            "    await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 1707, in run_server_worker\n",
            "    async with build_async_engine_client(args, client_config) as engine_client:\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 158, in build_async_engine_client\n",
            "    async with build_async_engine_client_from_engine_args(\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 291, in build_async_engine_client_from_engine_args\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Engine process failed to start. See stack trace for the root cause.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd voxtral-test && pwd && uv run transcribe.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOu4kVQCcvMI",
        "outputId": "c69f80c8-d7f0-4c69-bb82-fe1ad96737b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/voxtral-test\n",
            "\u001b[2K\u001b[1ATraceback (most recent call last):\n",
            "  File \"/content/voxtral-test/transcribe.py\", line 1, in <module>\n",
            "    from mistral_common.protocol.transcription.request import TranscriptionRequest\n",
            "ModuleNotFoundError: No module named 'mistral_common'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!  cd voxtral-test && pwd && uv run streaming.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFTcp98udISu",
        "outputId": "21d23275-b1af-42eb-ef76-748fe9f4c350"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/voxtral-test\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/voxtral-test/streaming.py\", line 1, in <module>\n",
            "    from mistral_common.protocol.transcription.request import TranscriptionRequest\n",
            "ModuleNotFoundError: No module named 'mistral_common'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cL5LJwPdNTO"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}